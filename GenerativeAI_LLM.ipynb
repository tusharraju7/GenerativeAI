{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4us2Umhd9f5M"
      },
      "source": [
        "# Mounting to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5ywUkd0MNb3",
        "outputId": "281c917f-680f-45da-e743-8a4713c1b595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQexC9b299tX"
      },
      "source": [
        "# Install latest version of Huggingface and import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbXOqrnXK9Hh",
        "outputId": "3d9c3d6c-1eaa-4c35-adec-1e877058f874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QmGKTFUl1Jb3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8790tgYT9eLv"
      },
      "source": [
        "Preparing the data for fine-tuning using OpenAI Playground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8fePXMKv8nng"
      },
      "outputs": [],
      "source": [
        "# Load training, test, and validation sets\n",
        "PATH = '/content/drive/MyDrive/LLM_Assignment'\n",
        "def load_data(PATH):\n",
        "  train_data = pd.read_csv(PATH + '/training.csv')\n",
        "  test_data = pd.read_csv(PATH + '/test.csv')\n",
        "  val_data = pd.read_csv(PATH + '/validation.csv')\n",
        "  return train_data, test_data, val_data\n",
        "\n",
        "train_data, test_data, val_data = load_data(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7dznAobyH8Sx",
        "outputId": "11e10da3-4680-4051-e4a3-7ec7a19d7a6b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"Domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Medical \",\n          \"CS \",\n          \"biochemistry \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 34,\n        \"samples\": [\n          \" Sports Injuries  \",\n          \" Human Metabolism  \",\n          \" Satellite radio  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \" gloves; individual prevention; hand eczema; massage; occupational exposure; occupational health; occupational skin diseases; protection measure        \",\n          \" Drug metabolism; human-chimeric mice; human liver; mouse liver; phase I enzymes; phase II enzymes; rat-chimeric mice        \",\n          \" angiotensin II; losartan; renovascular hypertension; tissue-specific inhibitor of metalloproteinase-2        \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"Background: Physiotherapists have an occupationally elevated risk of dermatoses. One aim of skin care seminars for specific professional groupsin individual prevention programme in Germany is to ensure appropriate use of safety measures during patient treatment. Initially physiotherapists often think skeptically about the use of gloves and patients' acceptance of this protective measure. So the objective of this study was to assess the practicality of glove use during physiotherapy (qualitative investigation) and customer acceptance of them during massage (quantitative investigation). Methods: Structured problem-focused interviews about glove usage were held with 20 skin diseased physiotherapists and masseurs after skin care seminars. The data was evaluated inductively using Mayring's qualitative content analysis. The clients' acceptance was tested in a controlled randomized three setting study with 120 subjects who received a back massage and evaluated quality aspects of their massage in a questionnaire. The physiotherapist was wearing either gloves of PVC, gloves made of nitrile rubber or no gloves at all. A non-inferiority test was used to test group differences. Result: The majority of participating physiotherapists considered the use of protective gloves a practical and useful measure. However, occasional problems in everyday practice and in special therapy methods were reported. The analysis of 120 questionnaires (100% response rate) for quality aspects and the willingness to pay regarding client acceptancein a massage - with or without gloves - showed a non-inferiority result for massages with gloves. Conclusion: Convincing individual physiotherapists of the benefits of wearing gloves is crucial for implementation of this preventive measure. It is improbable that patients would refuse services because therapists wear gloves during treatments. Consequently, the usage of gloves is unlikely to result in a loss of practice custom.\",\n          \"1. Human-chimeric mice with humanized liver have been constructed by transplantation of human hepatocytes into several types of mice having genetic modifications that injure endogenous liver cells. Here, we focus on liver urokinase-type plasminogen activator-transgenic severe combined immunodeficiency (uPA/SCID) mice, which are the most widely used human-chimeric mice. Studies so far indicate that drug metabolism, drug transport, pharmacological effects and toxicological action in these mice are broadly similar to those in humans. 2. Expression of various drug-metabolizing enzymes is known to be different between humans and rodents. However, the expression pattern of cytochrome P450, aldehyde oxidase and phase II enzymes in the liver of human-chimeric mice resembles that in humans, not that in the host mice. 3. Metabolism of various drugs, including S-warfarin, zaleplon, ibuprofen, naproxen, coumarin, troglitazone and midazolam, in human-chimeric mice is mediated by human drug-metabolizing enzymes, not by host mouse enzymes, and thus resembles that in humans. 4. Pharmacological and toxicological effects of various drugs in human-chimeric mice are also similar to those in humans. 5. The current consensus is that chimeric mice with humanized liver are useful to predict drug metabolism catalyzed by cytochrome P450, aldehyde oxidase and phase II enzymes in humans in vivo and in vitro. Some remaining issues are discussed in this review.\",\n          \"1. Angiotensin (Ang) II plays a major role in vascular remodelling. Matrix metalloproteinases (MMPs) and their tissue inhibitors (TIMPs) are involved in the tissue remodelling processes. The aim of the present study was to investigate whether AngII modulates TIMP-2 expression in rat aortic smooth muscle cells in vivo. 2. Angiotensin II (200 ng/kg per min, s.c.) or AngII + losartan (10 mg/kg per day, s.c.) or normal saline was administered continuously by osmotic minipumps to Sprague-Dawley rats for 1 week. In addition, the effect of endogenous AngII on TIMP-2 expression was evaluated in renovascular hypertensive rats (two kidney, one clip (2K1C) and one kidney, one clip (1K1C) models). Control rats (sham 2K1C and sham 1K1C rats) underwent sham-clipping of the left renal artery. At the end of the treatment, plasma renin activity was measured by radioimmunoassay, aortic TIMP-2 mRNA expression was evaluated by real-time polymerase chain reaction and/or northern blotting and protein expression was evaluated by immunohistochemistry. Systolic blood pressure (SBP) was measured twice a week by the tail-cuff method. 3. Exogenous AngII administration produced the expected increase in SBP (P = 0.02) compared with the control saline-treated group. The increase in SBP was abolished in AngII + losartan-treated rats. Administration of AngII caused a significant increase in TIMP-2 expression (P = 0.01) in rat aortic smooth muscle cells that was abolished in AngII + losartan-treated rats. In renovascular hypertensive rats, SBP was higher (P < 0.0001) in 2K1C and 1K1C rats compared with the corresponding sham-operated rats. Plasma renin activity was higher (P < 0.01) in 2K1C rats compared with the other groups. The expression of TIMP-2 was significantly (P < 0.05) increased only in 2K1C rats. 4. Our in vivo data demonstrate that exogenous and endogenous AngII increases TIMP-2 expression in rat aortic smooth muscle cells. This effect is not dependent on the AngII-induced increase in blood pressure and is mediated by angiotensin AT(1) receptors.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4c52a219-ab8e-4ccd-a9a8-0a147853ca7f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Domain</th>\n",
              "      <th>area</th>\n",
              "      <th>keywords</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Hepatitis C</td>\n",
              "      <td>Feasibility study; hepatitis C risk behaviour...</td>\n",
              "      <td>Aims: This study aimed to develop and test the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CS</td>\n",
              "      <td>Distributed computing</td>\n",
              "      <td>Agent Architecture; Mobile Agent; Agent Cloni...</td>\n",
              "      <td>Mobile agent technology is becoming more popul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ECE</td>\n",
              "      <td>Control engineering</td>\n",
              "      <td>educational software tool; multivariable cont...</td>\n",
              "      <td>This paper presents an educational software to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Psychology</td>\n",
              "      <td>False memories</td>\n",
              "      <td>judgment; metamemory; accuracy; eyewitness me...</td>\n",
              "      <td>Different researchers have reported positive, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Psychology</td>\n",
              "      <td>Leadership</td>\n",
              "      <td>Implementation support; Co-occurring disorder...</td>\n",
              "      <td>Background: Incorporating evidence-based integ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CS</td>\n",
              "      <td>Bioinformatics</td>\n",
              "      <td>secondary metabolism; bioinformatics; genome ...</td>\n",
              "      <td>The soil-borne gram-positive bacteria Aneurini...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Psychology</td>\n",
              "      <td>Depression</td>\n",
              "      <td>Adolescence; Expressed emotion; Psychopatholo...</td>\n",
              "      <td>Objective: To investigate the association betw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ECE</td>\n",
              "      <td>Electrical generator</td>\n",
              "      <td>CO2 capture; Efficiency; Exergy; LNG (liquefi...</td>\n",
              "      <td>The LNG (liquefied natural gas) regasification...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CS</td>\n",
              "      <td>Distributed computing</td>\n",
              "      <td>Quantum computing; Approximation algorithms; ...</td>\n",
              "      <td>We make use of a kind of distributed semi-quan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Ankylosing Spondylitis</td>\n",
              "      <td>Biologic agents; Registry; Rheumatoid arthrit...</td>\n",
              "      <td>Despite improved quality of care for rheumatoi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Depression</td>\n",
              "      <td>Multispectral imaging; Monte Carlo simulation...</td>\n",
              "      <td>We investigated a quantitative imaging of redu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Civil</td>\n",
              "      <td>Remote Sensing</td>\n",
              "      <td>Convolutional neural network (CNN); object lo...</td>\n",
              "      <td>In this paper, we focus on tackling the proble...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Northern blotting</td>\n",
              "      <td>Beet black scorch virus; infectious cDNA clon...</td>\n",
              "      <td>A full-length Beet black scorch virus (BBSV) c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Skin Care</td>\n",
              "      <td>gloves; individual prevention; hand eczema; m...</td>\n",
              "      <td>Background: Physiotherapists have an occupatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ECE</td>\n",
              "      <td>Electrical generator</td>\n",
              "      <td>Transverse flux; TFPM; Ocean wave energy; Low...</td>\n",
              "      <td>Modern energy demands led the scientific commu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Low Testosterone</td>\n",
              "      <td>Testosterone; Cardiovascular Diseases; Erecti...</td>\n",
              "      <td>Introduction Testosterone deficiency syndrome ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Civil</td>\n",
              "      <td>Remote Sensing</td>\n",
              "      <td>Moon; water; hydroxyl; infrared spectroscopy;...</td>\n",
              "      <td>Water and/or hydroxyl detected remotely on the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Skin Care</td>\n",
              "      <td>Collagen Peptides; Carboxymethyl Chitosan; Mi...</td>\n",
              "      <td>Type I collagen peptides were prepared by hydr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>MAE</td>\n",
              "      <td>Hydraulics</td>\n",
              "      <td>Hydropower station system; Coupled hydraulic-...</td>\n",
              "      <td>A nonlinear dynamic coupled model for hydropow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Psychology</td>\n",
              "      <td>Attention</td>\n",
              "      <td>ADHD; DRD4; DAT1; VNTR</td>\n",
              "      <td>The dopamine receptor-D4 and the dopamine tran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Sports Injuries</td>\n",
              "      <td>Sports injury; Athletes; Postural stability  ...</td>\n",
              "      <td>[Purpose] The aim of this study was to analyze...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Senior Health</td>\n",
              "      <td>Ankle range of motion; Balance; TETRAX</td>\n",
              "      <td>[Purpose] This study examined the influence of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>CS</td>\n",
              "      <td>Computer graphics</td>\n",
              "      <td>3D images; Virtual reality; Smoothness</td>\n",
              "      <td>[Purpose] This study verified that the smoothn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ECE</td>\n",
              "      <td>Digital control</td>\n",
              "      <td>active power filter; vector resonant controll...</td>\n",
              "      <td>\\There are many factors that affect the perfor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Human Metabolism</td>\n",
              "      <td>ALUMINUM; GALLIUM; INJECTION; RETENTION; EXCR...</td>\n",
              "      <td>1 Al-26 and Ga-67 were given as citrates to a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Polymerase chain reaction</td>\n",
              "      <td>1; 2-dicloropropane; dichloromethane; gpt del...</td>\n",
              "      <td>1,2-Dichloropropane (1,2-DCP) and dichlorometh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Multiple Sclerosis</td>\n",
              "      <td>Immunomodulation; Intestinal absorption; Bloo...</td>\n",
              "      <td>1,2-Dihydro-4-hydroxy-2-oxo-1,8-naphthyridine-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Human Metabolism</td>\n",
              "      <td>Chimeric mouse; liver; (uPA plus / plus )/SCI...</td>\n",
              "      <td>1. A model that predicts human metabolism and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Human Metabolism</td>\n",
              "      <td>Chimeric mouse; chymase inhibitor; clinical s...</td>\n",
              "      <td>1. A novel oral chymase inhibitor, SUN13834, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Psychology</td>\n",
              "      <td>Prenatal development</td>\n",
              "      <td>female alternative morphotype; female masculi...</td>\n",
              "      <td>1. Alternative morphotypes have been reported ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Northern blotting</td>\n",
              "      <td>angiotensin II; losartan; renovascular hypert...</td>\n",
              "      <td>1. Angiotensin (Ang) II plays a major role in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>CS</td>\n",
              "      <td>Operating systems</td>\n",
              "      <td>biodiversity surveys; camera trapping; data m...</td>\n",
              "      <td>1. Camera trapping is a widely applied method ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>ECE</td>\n",
              "      <td>Microcontroller</td>\n",
              "      <td>applied ecology; disease ecology; incubator; ...</td>\n",
              "      <td>1. Commercially available fluctuating-temperat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Enzymology</td>\n",
              "      <td>Cyadox; pigs; cyadox monoxide; N-oxides; N-ox...</td>\n",
              "      <td>1. Cyadox is a novel quinoxaline-1,4-dioxide w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Psychology</td>\n",
              "      <td>Attention</td>\n",
              "      <td>Daphnetin; COMT inhibitor; 8-O-methyldaphneti...</td>\n",
              "      <td>1. Finding and developing inhibitors of catech...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Immunology</td>\n",
              "      <td>Asecodes; cellular defence; ecological immuno...</td>\n",
              "      <td>1. Host-parasitoid systems are characterized b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>ECE</td>\n",
              "      <td>Satellite radio</td>\n",
              "      <td>animal movement; area-restricted search; Argo...</td>\n",
              "      <td>1. How and at what spatial scale(s) animals ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Northern blotting</td>\n",
              "      <td>ATP binding cassette (ABC) transporter; cloni...</td>\n",
              "      <td>1. Human ABCA8, a new member of the ATP bindin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Human Metabolism</td>\n",
              "      <td>Aldehyde oxidase; cytochrome P450; human live...</td>\n",
              "      <td>1. Human chimeric mice (h-PXB mice) having hum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Human Metabolism</td>\n",
              "      <td>Drug metabolism; human-chimeric mice; human l...</td>\n",
              "      <td>1. Human-chimeric mice with humanized liver ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Genetics</td>\n",
              "      <td>carbon; ecosystem function; ecosystem structu...</td>\n",
              "      <td>1. Individual plant genotypes as well as genot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Civil</td>\n",
              "      <td>Green Building</td>\n",
              "      <td>social innovation; schools of sustainability;...</td>\n",
              "      <td>1. INTRODUCTION Sustainability has been define...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Civil</td>\n",
              "      <td>Green Building</td>\n",
              "      <td>Sustainability; Energy Conservation; Passive ...</td>\n",
              "      <td>1. INTRODUCTION The emergence of environmental...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Civil</td>\n",
              "      <td>Water Pollution</td>\n",
              "      <td>marine; freshwater; Red List; springs; coral ...</td>\n",
              "      <td>1. Invertebrates inhabiting marine and freshwa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>MAE</td>\n",
              "      <td>Hydraulics</td>\n",
              "      <td>elevated CO2; eucalyptus; genotype; leaf econ...</td>\n",
              "      <td>1. Leaf economics and hydraulic traits strongl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Hepatitis C</td>\n",
              "      <td>CYP3A1; disposition; docetaxel; liver injury;...</td>\n",
              "      <td>1. Magnesium isoglycyrrhizinate (MgIg) has bee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Human Metabolism</td>\n",
              "      <td>ABT-107; cytochrome P450; FMO; species differ...</td>\n",
              "      <td>1. Metabolism of ABT-107 was investigated in i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Molecular biology</td>\n",
              "      <td>Disposition; homoharringtonine; mepesuccinate...</td>\n",
              "      <td>1. Omacetaxine mepesuccinate (hereafter referr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Weight Loss</td>\n",
              "      <td>Diapause; hymenoptera; multiple stresses; pol...</td>\n",
              "      <td>1. Seasonal adaptations enabling the bridging ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>MAE</td>\n",
              "      <td>Strength of materials</td>\n",
              "      <td>porous sound-absorbing material; curing techn...</td>\n",
              "      <td>A series of different volume-weights of Silica...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c52a219-ab8e-4ccd-a9a8-0a147853ca7f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c52a219-ab8e-4ccd-a9a8-0a147853ca7f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c52a219-ab8e-4ccd-a9a8-0a147853ca7f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ae49d003-3860-4a34-819f-e28d3d77cee6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae49d003-3860-4a34-819f-e28d3d77cee6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ae49d003-3860-4a34-819f-e28d3d77cee6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6a7e13ae-d984-4f02-af1b-631bea1712f1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6a7e13ae-d984-4f02-af1b-631bea1712f1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           Domain                          area  \\\n",
              "0        Medical                  Hepatitis C     \n",
              "1             CS        Distributed computing     \n",
              "2            ECE          Control engineering     \n",
              "3    Psychology                False memories     \n",
              "4    Psychology                    Leadership     \n",
              "5             CS               Bioinformatics     \n",
              "6    Psychology                    Depression     \n",
              "7            ECE         Electrical generator     \n",
              "8             CS        Distributed computing     \n",
              "9        Medical       Ankylosing Spondylitis     \n",
              "10       Medical                   Depression     \n",
              "11         Civil               Remote Sensing     \n",
              "12  biochemistry            Northern blotting     \n",
              "13       Medical                    Skin Care     \n",
              "14           ECE         Electrical generator     \n",
              "15       Medical             Low Testosterone     \n",
              "16         Civil               Remote Sensing     \n",
              "17       Medical                    Skin Care     \n",
              "18           MAE                   Hydraulics     \n",
              "19   Psychology                     Attention     \n",
              "20       Medical              Sports Injuries     \n",
              "21       Medical                Senior Health     \n",
              "22            CS            Computer graphics     \n",
              "23           ECE              Digital control     \n",
              "24  biochemistry             Human Metabolism     \n",
              "25  biochemistry    Polymerase chain reaction     \n",
              "26       Medical           Multiple Sclerosis     \n",
              "27  biochemistry             Human Metabolism     \n",
              "28  biochemistry             Human Metabolism     \n",
              "29   Psychology          Prenatal development     \n",
              "30  biochemistry            Northern blotting     \n",
              "31            CS            Operating systems     \n",
              "32           ECE              Microcontroller     \n",
              "33  biochemistry                   Enzymology     \n",
              "34   Psychology                     Attention     \n",
              "35  biochemistry                   Immunology     \n",
              "36           ECE              Satellite radio     \n",
              "37  biochemistry            Northern blotting     \n",
              "38  biochemistry             Human Metabolism     \n",
              "39  biochemistry             Human Metabolism     \n",
              "40  biochemistry                     Genetics     \n",
              "41         Civil               Green Building     \n",
              "42         Civil               Green Building     \n",
              "43         Civil              Water Pollution     \n",
              "44           MAE                   Hydraulics     \n",
              "45       Medical                  Hepatitis C     \n",
              "46  biochemistry             Human Metabolism     \n",
              "47  biochemistry            Molecular biology     \n",
              "48       Medical                  Weight Loss     \n",
              "49           MAE        Strength of materials     \n",
              "\n",
              "                                             keywords  \\\n",
              "0    Feasibility study; hepatitis C risk behaviour...   \n",
              "1    Agent Architecture; Mobile Agent; Agent Cloni...   \n",
              "2    educational software tool; multivariable cont...   \n",
              "3    judgment; metamemory; accuracy; eyewitness me...   \n",
              "4    Implementation support; Co-occurring disorder...   \n",
              "5    secondary metabolism; bioinformatics; genome ...   \n",
              "6    Adolescence; Expressed emotion; Psychopatholo...   \n",
              "7    CO2 capture; Efficiency; Exergy; LNG (liquefi...   \n",
              "8    Quantum computing; Approximation algorithms; ...   \n",
              "9    Biologic agents; Registry; Rheumatoid arthrit...   \n",
              "10   Multispectral imaging; Monte Carlo simulation...   \n",
              "11   Convolutional neural network (CNN); object lo...   \n",
              "12   Beet black scorch virus; infectious cDNA clon...   \n",
              "13   gloves; individual prevention; hand eczema; m...   \n",
              "14   Transverse flux; TFPM; Ocean wave energy; Low...   \n",
              "15   Testosterone; Cardiovascular Diseases; Erecti...   \n",
              "16   Moon; water; hydroxyl; infrared spectroscopy;...   \n",
              "17   Collagen Peptides; Carboxymethyl Chitosan; Mi...   \n",
              "18   Hydropower station system; Coupled hydraulic-...   \n",
              "19                     ADHD; DRD4; DAT1; VNTR           \n",
              "20   Sports injury; Athletes; Postural stability  ...   \n",
              "21     Ankle range of motion; Balance; TETRAX           \n",
              "22     3D images; Virtual reality; Smoothness           \n",
              "23   active power filter; vector resonant controll...   \n",
              "24   ALUMINUM; GALLIUM; INJECTION; RETENTION; EXCR...   \n",
              "25   1; 2-dicloropropane; dichloromethane; gpt del...   \n",
              "26   Immunomodulation; Intestinal absorption; Bloo...   \n",
              "27   Chimeric mouse; liver; (uPA plus / plus )/SCI...   \n",
              "28   Chimeric mouse; chymase inhibitor; clinical s...   \n",
              "29   female alternative morphotype; female masculi...   \n",
              "30   angiotensin II; losartan; renovascular hypert...   \n",
              "31   biodiversity surveys; camera trapping; data m...   \n",
              "32   applied ecology; disease ecology; incubator; ...   \n",
              "33   Cyadox; pigs; cyadox monoxide; N-oxides; N-ox...   \n",
              "34   Daphnetin; COMT inhibitor; 8-O-methyldaphneti...   \n",
              "35   Asecodes; cellular defence; ecological immuno...   \n",
              "36   animal movement; area-restricted search; Argo...   \n",
              "37   ATP binding cassette (ABC) transporter; cloni...   \n",
              "38   Aldehyde oxidase; cytochrome P450; human live...   \n",
              "39   Drug metabolism; human-chimeric mice; human l...   \n",
              "40   carbon; ecosystem function; ecosystem structu...   \n",
              "41   social innovation; schools of sustainability;...   \n",
              "42   Sustainability; Energy Conservation; Passive ...   \n",
              "43   marine; freshwater; Red List; springs; coral ...   \n",
              "44   elevated CO2; eucalyptus; genotype; leaf econ...   \n",
              "45   CYP3A1; disposition; docetaxel; liver injury;...   \n",
              "46   ABT-107; cytochrome P450; FMO; species differ...   \n",
              "47   Disposition; homoharringtonine; mepesuccinate...   \n",
              "48   Diapause; hymenoptera; multiple stresses; pol...   \n",
              "49   porous sound-absorbing material; curing techn...   \n",
              "\n",
              "                                             Abstract  \n",
              "0   Aims: This study aimed to develop and test the...  \n",
              "1   Mobile agent technology is becoming more popul...  \n",
              "2   This paper presents an educational software to...  \n",
              "3   Different researchers have reported positive, ...  \n",
              "4   Background: Incorporating evidence-based integ...  \n",
              "5   The soil-borne gram-positive bacteria Aneurini...  \n",
              "6   Objective: To investigate the association betw...  \n",
              "7   The LNG (liquefied natural gas) regasification...  \n",
              "8   We make use of a kind of distributed semi-quan...  \n",
              "9   Despite improved quality of care for rheumatoi...  \n",
              "10  We investigated a quantitative imaging of redu...  \n",
              "11  In this paper, we focus on tackling the proble...  \n",
              "12  A full-length Beet black scorch virus (BBSV) c...  \n",
              "13  Background: Physiotherapists have an occupatio...  \n",
              "14  Modern energy demands led the scientific commu...  \n",
              "15  Introduction Testosterone deficiency syndrome ...  \n",
              "16  Water and/or hydroxyl detected remotely on the...  \n",
              "17  Type I collagen peptides were prepared by hydr...  \n",
              "18  A nonlinear dynamic coupled model for hydropow...  \n",
              "19  The dopamine receptor-D4 and the dopamine tran...  \n",
              "20  [Purpose] The aim of this study was to analyze...  \n",
              "21  [Purpose] This study examined the influence of...  \n",
              "22  [Purpose] This study verified that the smoothn...  \n",
              "23  \\There are many factors that affect the perfor...  \n",
              "24  1 Al-26 and Ga-67 were given as citrates to a ...  \n",
              "25  1,2-Dichloropropane (1,2-DCP) and dichlorometh...  \n",
              "26  1,2-Dihydro-4-hydroxy-2-oxo-1,8-naphthyridine-...  \n",
              "27  1. A model that predicts human metabolism and ...  \n",
              "28  1. A novel oral chymase inhibitor, SUN13834, i...  \n",
              "29  1. Alternative morphotypes have been reported ...  \n",
              "30  1. Angiotensin (Ang) II plays a major role in ...  \n",
              "31  1. Camera trapping is a widely applied method ...  \n",
              "32  1. Commercially available fluctuating-temperat...  \n",
              "33  1. Cyadox is a novel quinoxaline-1,4-dioxide w...  \n",
              "34  1. Finding and developing inhibitors of catech...  \n",
              "35  1. Host-parasitoid systems are characterized b...  \n",
              "36  1. How and at what spatial scale(s) animals ch...  \n",
              "37  1. Human ABCA8, a new member of the ATP bindin...  \n",
              "38  1. Human chimeric mice (h-PXB mice) having hum...  \n",
              "39  1. Human-chimeric mice with humanized liver ha...  \n",
              "40  1. Individual plant genotypes as well as genot...  \n",
              "41  1. INTRODUCTION Sustainability has been define...  \n",
              "42  1. INTRODUCTION The emergence of environmental...  \n",
              "43  1. Invertebrates inhabiting marine and freshwa...  \n",
              "44  1. Leaf economics and hydraulic traits strongl...  \n",
              "45  1. Magnesium isoglycyrrhizinate (MgIg) has bee...  \n",
              "46  1. Metabolism of ABT-107 was investigated in i...  \n",
              "47  1. Omacetaxine mepesuccinate (hereafter referr...  \n",
              "48  1. Seasonal adaptations enabling the bridging ...  \n",
              "49  A series of different volume-weights of Silica...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Formatting Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcfnD_-s8yc2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_finetuning_data_gpt(dataset):\n",
        "    abstracts = dataset['Abstract']\n",
        "    domains = dataset['Domain']\n",
        "    classified_data = []\n",
        "    for abstract, domain in zip(abstracts, domains):\n",
        "        message = {\"messages\": []}\n",
        "        message[\"messages\"].append({\"role\": \"user\", \"content\": abstract})\n",
        "        message[\"messages\"].append({\"role\": \"assistant\", \"content\": domain})\n",
        "        classified_data.append(message)\n",
        "    return classified_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZZ35QFlJ1dF"
      },
      "outputs": [],
      "source": [
        "processed_train_data = make_finetuning_data_gpt(train_data)\n",
        "processed_val_data = make_finetuning_data_gpt(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibFPIDR5J1fr"
      },
      "outputs": [],
      "source": [
        "with open(PATH + '/training.jsonl', 'w') as f:\n",
        "    for item in processed_train_data:\n",
        "        json.dump(item, f)\n",
        "        f.write('\\n')  # Write a newline character to separate JSON objects\n",
        "\n",
        "# Save validation data to JSONL\n",
        "with open(PATH + '/validation.jsonl', 'w') as f:\n",
        "    for item in processed_val_data:\n",
        "        json.dump(item, f)\n",
        "        f.write('\\n')  # Write a newline character to separate JSON objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3_bCj6iM0qw"
      },
      "source": [
        "Fine Tuning a Distilbert model on the training set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk6iSRegd_Xd"
      },
      "outputs": [],
      "source": [
        "training_set, test_set, validation_set = load_data(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrxQz6-SwPJe"
      },
      "outputs": [],
      "source": [
        "training_set['sample'] = 'training'\n",
        "validation_set['sample'] = 'validation'\n",
        "test_set['sample'] = 'test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHGaLUUJkJrc"
      },
      "outputs": [],
      "source": [
        "num_classes = training_set['Domain'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PymsRTvyyHDT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "all_sets = pd.concat([training_set, validation_set, test_set], axis=0)\n",
        "\n",
        "# Encode Domain column\n",
        "label_encoder = LabelEncoder()\n",
        "all_sets['Encoded_Domain'] = label_encoder.fit_transform(all_sets['Domain'])\n",
        "\n",
        "# Split back into individual sets\n",
        "training_set = all_sets[all_sets['sample'] == 'training']\n",
        "validation_set = all_sets[all_sets['sample'] == 'validation']\n",
        "test_set = all_sets[all_sets['sample'] == 'test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "_W0zCp3VwDXD",
        "outputId": "3a2b510e-2438-47e2-c419-8b0e81a90a4a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"test_set\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"CS \",\n          \"Civil \",\n          \"MAE \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \" Data structures  \",\n          \" Bioinformatics  \",\n          \" Hydraulics  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \" In-memory XPath processing; NESTOR; Set-based data models; Data structures        \",\n          \" Bpifb1; parotid acinar cells; NOD mouse        \",\n          \" Mild cognitive impairment; Alzheimer's disease; Magnetic resonance spectroscopy; Brain volumetry        \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"XML is a pervasive technology for representing and accessing semi-structured data. XPath is the standard language for navigational queries on XML documents and there is a growing demand for its efficient processing. In order to increase the efficiency in executing four navigational XML query primitives, namely descendants, ancestors, children and parent, we introduce a new paradigm where traditional approaches based on the efficient traversing of nodes and edges to reconstruct the requested subtrees are replaced by a brand new one based on basic set operations which allow us to directly return the desired subtree, avoiding to create it passing through nodes and edges. Our solution stems from the NEsted SeTs for Object hieRarchies (NEASTOR) formal model, which makes use of set-inclusion relations for representing and providing access to hierarchical data. We define in-memory efficient data structures to implement NESTOR, we develop algorithms to perform the descendants, ancestors, children and parent query primitives and we study their computational complexity. We conduct an extensive experimental evaluation by using several datasets: digital archives (EAD collections), INEX 2009 Wikipedia collection, and two widely-used synthetic datasets (XMark and XGen). We show that NESTOR-based data structures and query primitives consistently outperform state-of-the-art solutions for XPath processing at execution time and they are competitive in terms of both memory occupation and pre-processing time. (C) 2015 Elsevier Ltd. All rights reserved.\",\n          \"OBJECTIVE: To define the increased mRNA expression of Bpifb1, a member of the bactericidal/permeability-increasing protein family, in parotid acinar cells from non-obese diabetic (NOD) mice, an animal model for Sjogren's syndrome. MATERIALS AND METHODS: Parotid acinar cells were prepared from female NOD (NOD/ShiJcl) mice with or without diabetes, as well as from control (C57BL/6JJcl) mice. Total RNA and homogenate were prepared from the parotid acinar cells. Embryonic cDNA from a Mouse MTC (TM) Panel I kit was used. The expression of Bpifb1 was determined by cDNA microarray analysis, RT-PCR, real-time PCR, northern blotting and in situ hybridization. RESULTS: The expression of Bpifb1 mRNA was high in parotid acinar cells from diabetic and non-diabetic NOD mice at 5-50 weeks of age. Acinar cells in the C57BL/6 mice had a low expression of Bpifb1 mRNA at an age >8 weeks, but had a relatively high expression in the foetus and infantile stages. CONCLUSIONS: Bpifb1 mRNA is upregulated in parotid acinar cells in NOD mice, but its expression is not related to the onset of diabetes. These findings suggest that high expression levels of Bpifb1 might predict disease traits before the onset of autoimmunity.\",\n          \"Objective: To assess the accuracy of magnetic resonance spectroscopy (1H-MRS) and brain volumetry in mild cognitive impairment (MCI) to predict conversion to probable Alzheimer's disease (AD). Methods: Forty-eight patients fulfilling the criteria of amnestic MCI who underwent a conventional magnetic resonance imaging (MRI) followed by MRS, and T1-3D on 1.5 Tesla MR unit. At baseline the patients underwent neuropsychological examination. 1H-MRS of the brain was carried out by exploring the left medial occipital lobe and ventral posterior cingulated cortex (vPCC) using the LCModel software. A high resolution T1-3D sequence was acquired to carry out the volumetric measurement. A cortical and subcortical parcellation strategy was used to obtain the volumes of each area within the brain. The patients were followed up to detect conversion to probable AD. Results: After a 3-year follow-up, 15 (31.2%) patients converted to AD. The myo-inositol in the occipital cortex and glutamate + glutamine (Glx) in the posterior cingulate cortex predicted conversion to probable AD at 46.1% sensitivity and 90.6% specificity. The positive predictive value was 66.7%, and the negative predictive value was 80.6%, with an overall cross-validated classification accuracy of 77.8%. The volume of the third ventricle, the total white matter and entorhinal cortex predict conversion to probable AD at 46.7% sensitivity and 90.9% specificity. The positive predictive value was 70%, and the negative predictive value was 78.9%, with an overall cross validated classification accuracy of 77.1%. Combining volumetric measures in addition to the MRS measures the prediction to probable AD has a 38.5% sensitivity and 87.5% specificity, with a positive predictive value of 55.6%, a negative predictive value of 77.8% and an overall accuracy of 733%. Conclusion: Either MRS or brain volumetric measures are markers separately of cognitive decline and may serve as a noninvasive tool to monitor cognitive changes and progression to dementia in patients with amnestic MCI, but the results do not support the routine use in the clinical settings. (C) 2016 Elsevier Inc. All rights reserved.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sample\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Encoded_Domain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "test_set"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-38e94092-a2b0-4938-ab5f-97af9eff17d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Domain</th>\n",
              "      <th>area</th>\n",
              "      <th>keywords</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>sample</th>\n",
              "      <th>Encoded_Domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CS</td>\n",
              "      <td>Data structures</td>\n",
              "      <td>In-memory XPath processing; NESTOR; Set-based...</td>\n",
              "      <td>XML is a pervasive technology for representing...</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Civil</td>\n",
              "      <td>Ambient Intelligence</td>\n",
              "      <td>Home energy management; persuasive interface;...</td>\n",
              "      <td>The integration of renewable energy sources in...</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ECE</td>\n",
              "      <td>Electrical generator</td>\n",
              "      <td>non-standard electrical machine; generation o...</td>\n",
              "      <td>The original free-swinging piston engine with ...</td>\n",
              "      <td>test</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Hepatitis C</td>\n",
              "      <td>complications; patient engagement; patient-ce...</td>\n",
              "      <td>Barriers to access and long-term complications...</td>\n",
              "      <td>test</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ECE</td>\n",
              "      <td>Control engineering</td>\n",
              "      <td>force feedback haptic interface; virtual real...</td>\n",
              "      <td>This paper is to present a technological solut...</td>\n",
              "      <td>test</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CS</td>\n",
              "      <td>Bioinformatics</td>\n",
              "      <td>Bioinformatics; genomics</td>\n",
              "      <td>Transposable elements (TEs) constitute the mos...</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Weight Loss</td>\n",
              "      <td>Obesity; weight loss; moral work; body projec...</td>\n",
              "      <td>Cultural notions equating greater morality and...</td>\n",
              "      <td>test</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Psychology</td>\n",
              "      <td>Leadership</td>\n",
              "      <td>Data-based decision making; school improvemen...</td>\n",
              "      <td>Although data-based decision making can lead t...</td>\n",
              "      <td>test</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Psychology</td>\n",
              "      <td>Seasonal affective disorder</td>\n",
              "      <td>Ramelteon; sleep; agomelatine; depression; in...</td>\n",
              "      <td>Insomnia is common among elderly people and ne...</td>\n",
              "      <td>test</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CS</td>\n",
              "      <td>Data structures</td>\n",
              "      <td>Succinct dynamic data structures; Succinct tr...</td>\n",
              "      <td>Cardinal trees (or tries of degree ) are a fun...</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Atrial Fibrillation</td>\n",
              "      <td>Transesophageal echocardiogram; Speckletracki...</td>\n",
              "      <td>Vascular mechanics assessed with two-dimension...</td>\n",
              "      <td>test</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CS</td>\n",
              "      <td>Distributed computing</td>\n",
              "      <td>Topology recognition; Leader election; Colore...</td>\n",
              "      <td>Topology recognition and leader election are f...</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>MAE</td>\n",
              "      <td>Hydraulics</td>\n",
              "      <td>RETRAN-3D; Heat transfer; Condensation; Therm...</td>\n",
              "      <td>The Great East Japan Earthquake occurred on Ma...</td>\n",
              "      <td>test</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ECE</td>\n",
              "      <td>Electric motor</td>\n",
              "      <td>Contra-rotating fan; gearless; computational ...</td>\n",
              "      <td>A gearless one-motor concept for contra-rotati...</td>\n",
              "      <td>test</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Psychology</td>\n",
              "      <td>Prosocial behavior</td>\n",
              "      <td>inequity aversion; generosity; partiality; fa...</td>\n",
              "      <td>Children and adults respond negatively to ineq...</td>\n",
              "      <td>test</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Medical</td>\n",
              "      <td>Alzheimer's Disease</td>\n",
              "      <td>Mild cognitive impairment; Alzheimer's diseas...</td>\n",
              "      <td>Objective: To assess the accuracy of magnetic ...</td>\n",
              "      <td>test</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Civil</td>\n",
              "      <td>Geotextile</td>\n",
              "      <td>Shear strength; Geosynthetic; Deposition plan...</td>\n",
              "      <td>The influence of the sand placement method abo...</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>biochemistry</td>\n",
              "      <td>Northern blotting</td>\n",
              "      <td>Bpifb1; parotid acinar cells; NOD mouse</td>\n",
              "      <td>OBJECTIVE: To define the increased mRNA expres...</td>\n",
              "      <td>test</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Civil</td>\n",
              "      <td>Remote Sensing</td>\n",
              "      <td>Soil moisture and ocean salinity (SMOS); Sea ...</td>\n",
              "      <td>The Soil Moisture and Ocean Salinity (SMOS) mi...</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Civil</td>\n",
              "      <td>Smart Material</td>\n",
              "      <td>shape-memory alloy; titanium-nickel alloy; su...</td>\n",
              "      <td>A SHAPE-MEMORY ALLOY (SMA) is expected to be a...</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38e94092-a2b0-4938-ab5f-97af9eff17d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38e94092-a2b0-4938-ab5f-97af9eff17d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38e94092-a2b0-4938-ab5f-97af9eff17d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b23380dc-6b95-4661-8bd2-471659f09b00\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b23380dc-6b95-4661-8bd2-471659f09b00')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b23380dc-6b95-4661-8bd2-471659f09b00 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f37c0c69-05d4-4048-99a7-4d5948eaca03\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_set')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f37c0c69-05d4-4048-99a7-4d5948eaca03 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_set');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           Domain                            area  \\\n",
              "0             CS                Data structures     \n",
              "1          Civil           Ambient Intelligence     \n",
              "2            ECE           Electrical generator     \n",
              "3        Medical                    Hepatitis C     \n",
              "4            ECE            Control engineering     \n",
              "5             CS                 Bioinformatics     \n",
              "6        Medical                    Weight Loss     \n",
              "7    Psychology                      Leadership     \n",
              "8    Psychology     Seasonal affective disorder     \n",
              "9             CS                Data structures     \n",
              "10       Medical            Atrial Fibrillation     \n",
              "11            CS          Distributed computing     \n",
              "12           MAE                     Hydraulics     \n",
              "13           ECE                 Electric motor     \n",
              "14   Psychology              Prosocial behavior     \n",
              "15       Medical            Alzheimer's Disease     \n",
              "16         Civil                     Geotextile     \n",
              "17  biochemistry              Northern blotting     \n",
              "18         Civil                 Remote Sensing     \n",
              "19         Civil                 Smart Material     \n",
              "\n",
              "                                             keywords  \\\n",
              "0    In-memory XPath processing; NESTOR; Set-based...   \n",
              "1    Home energy management; persuasive interface;...   \n",
              "2    non-standard electrical machine; generation o...   \n",
              "3    complications; patient engagement; patient-ce...   \n",
              "4    force feedback haptic interface; virtual real...   \n",
              "5                    Bioinformatics; genomics           \n",
              "6    Obesity; weight loss; moral work; body projec...   \n",
              "7    Data-based decision making; school improvemen...   \n",
              "8    Ramelteon; sleep; agomelatine; depression; in...   \n",
              "9    Succinct dynamic data structures; Succinct tr...   \n",
              "10   Transesophageal echocardiogram; Speckletracki...   \n",
              "11   Topology recognition; Leader election; Colore...   \n",
              "12   RETRAN-3D; Heat transfer; Condensation; Therm...   \n",
              "13   Contra-rotating fan; gearless; computational ...   \n",
              "14   inequity aversion; generosity; partiality; fa...   \n",
              "15   Mild cognitive impairment; Alzheimer's diseas...   \n",
              "16   Shear strength; Geosynthetic; Deposition plan...   \n",
              "17    Bpifb1; parotid acinar cells; NOD mouse           \n",
              "18   Soil moisture and ocean salinity (SMOS); Sea ...   \n",
              "19   shape-memory alloy; titanium-nickel alloy; su...   \n",
              "\n",
              "                                             Abstract sample  Encoded_Domain  \n",
              "0   XML is a pervasive technology for representing...   test               0  \n",
              "1   The integration of renewable energy sources in...   test               1  \n",
              "2   The original free-swinging piston engine with ...   test               2  \n",
              "3   Barriers to access and long-term complications...   test               4  \n",
              "4   This paper is to present a technological solut...   test               2  \n",
              "5   Transposable elements (TEs) constitute the mos...   test               0  \n",
              "6   Cultural notions equating greater morality and...   test               4  \n",
              "7   Although data-based decision making can lead t...   test               5  \n",
              "8   Insomnia is common among elderly people and ne...   test               5  \n",
              "9   Cardinal trees (or tries of degree ) are a fun...   test               0  \n",
              "10  Vascular mechanics assessed with two-dimension...   test               4  \n",
              "11  Topology recognition and leader election are f...   test               0  \n",
              "12  The Great East Japan Earthquake occurred on Ma...   test               3  \n",
              "13  A gearless one-motor concept for contra-rotati...   test               2  \n",
              "14  Children and adults respond negatively to ineq...   test               5  \n",
              "15  Objective: To assess the accuracy of magnetic ...   test               4  \n",
              "16  The influence of the sand placement method abo...   test               1  \n",
              "17  OBJECTIVE: To define the increased mRNA expres...   test               6  \n",
              "18  The Soil Moisture and Ocean Salinity (SMOS) mi...   test               1  \n",
              "19  A SHAPE-MEMORY ALLOY (SMA) is expected to be a...   test               1  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAvRmz5_xAzj",
        "outputId": "d3ba57b3-90ce-4e06-f4f2-a47c66b461e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def make_finetuning_data_distilbert(dataset):\n",
        "\n",
        "    labels = dataset['Encoded_Domain'].values\n",
        "\n",
        "    encoded = tokenizer.batch_encode_plus(\n",
        "        dataset['Abstract'],\n",
        "        add_special_tokens=True,\n",
        "        return_attention_mask=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    # Create a tensor dataset\n",
        "    return {\n",
        "        'input_ids': encoded['input_ids'],\n",
        "        'attention_mask': encoded['attention_mask'],\n",
        "        'labels': torch.tensor(labels)\n",
        "    }\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "bert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "training_set = make_finetuning_data_distilbert(training_set)\n",
        "validation_set = make_finetuning_data_distilbert(validation_set)\n",
        "test_set = make_finetuning_data_distilbert(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akWkecsS_pH_"
      },
      "source": [
        "Preparing the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsBfhI30BV-m"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE_TRAIN = 32\n",
        "BATCH_SIZE_VAL = 16\n",
        "BATCH_SIZE_TEST = 16\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "class FTDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data['input_ids'])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'input_ids': self.data['input_ids'][index],\n",
        "            'attention_mask': self.data['attention_mask'][index],\n",
        "            'labels': self.data['labels'][index]\n",
        "        }\n",
        "\n",
        "dataset_train = FTDataset(training_set)\n",
        "dataloader_train = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE_TRAIN)\n",
        "dataset_val = FTDataset(validation_set)\n",
        "dataloader_val = DataLoader(dataset=dataset_val, batch_size=BATCH_SIZE_VAL)\n",
        "dataset_test = FTDataset(test_set)\n",
        "dataloader_test = DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE_TEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtWqFZ41v1Xa",
        "outputId": "5d5a7325-6f03-4422-bb85-7135ab497290"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101, 20950,  2003,  ...,  1998,  7926,   102],\n",
              "         [  101,  1996,  8346,  ...,  1010,  1999,   102],\n",
              "         [  101,  1996,  2434,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,  7863,  1024,  ...,  2099,  4442,   102],\n",
              "         [  101,  1996,  5800,  ..., 13589, 13827,   102],\n",
              "         [  101,  1037,  4338,  ...,  1010,  4525,   102]]),\n",
              " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
              " 'labels': tensor([0, 1, 2, 4, 2, 0, 4, 5, 5, 0, 4, 0, 3, 2, 5, 4, 1, 6, 1, 1])}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D2KTsRSAOsd"
      },
      "source": [
        "Adding a trainable layer(s) on top of DistilBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "728UP_AvCcAZ"
      },
      "outputs": [],
      "source": [
        "class FTModel(nn.Module):\n",
        "    def __init__(self, bert_model):\n",
        "        super(FTModel, self).__init__()\n",
        "        self.bert_model = bert_model\n",
        "        self.dropout = nn.Dropout(0.1)  # Dropout layer for regularization\n",
        "        self.classifier = nn.Linear(bert_model.config.hidden_size, num_classes)  # Add a linear layer for classification\n",
        "        self.softmax = nn.Softmax(dim=1)  # Softmax activation for multi-class classification\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Use the [CLS] token embedding as the pooled output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        probabilities = self.softmax(logits)\n",
        "        return logits, probabilities\n",
        "\n",
        "# Create an instance of the FTModel\n",
        "model = FTModel(bert_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-BFVGXg7eS1"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 2e-5\n",
        "# Use cross-entropy loss\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize Optimizer\n",
        "optimizer= optim.Adam(model.parameters(),lr= LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DisQOmG1DK3T"
      },
      "outputs": [],
      "source": [
        "# Freeze parameters of the pre-trained Distilbert model\n",
        "for param in model.bert_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7YKz80RAvPV"
      },
      "source": [
        "Fine-tuning and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2i01ErB2dCH"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuhlrE_dDO9y",
        "outputId": "11fdb869-ceae-4f73-87ba-690ce55e518d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.130968928337097\n",
            "Validation Loss: 2.268948554992676, Accuracy: 0.08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0794063210487366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.1097753047943115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0849048495292664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.093376874923706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.11032497882843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.1011794209480286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.104034900665283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0867156982421875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0707375407218933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0601966977119446\n",
            "Validation Loss: 2.211119055747986, Accuracy: 0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.080949902534485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0540565252304077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0601508021354675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.057281732559204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0723517537117004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0113415718078613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0427663326263428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.042474389076233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0490405559539795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0548046827316284\n",
            "Validation Loss: 2.156253695487976, Accuracy: 0.16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0472235679626465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.005276679992676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0358265042304993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0334011912345886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0295369029045105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.022941470146179\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.036886215209961\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.028301477432251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9864330291748047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9940831065177917\n",
            "Validation Loss: 2.104207992553711, Accuracy: 0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.015466570854187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.008911430835724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 2.0022271275520325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9873091578483582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9998385906219482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9884308576583862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9916867017745972\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9727020263671875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9759047031402588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9875507354736328\n",
            "Validation Loss: 2.055089980363846, Accuracy: 0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9597914218902588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.948026955127716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9632987976074219\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9788766503334045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9612272381782532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9548190236091614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9422082901000977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9484710693359375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.955627977848053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9674879908561707\n",
            "Validation Loss: 2.008765935897827, Accuracy: 0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9545987248420715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9452161192893982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.946256399154663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9439070224761963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9163551330566406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9503085017204285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9087671041488647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.942805528640747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9389869570732117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.937722384929657\n",
            "Validation Loss: 1.9649399816989899, Accuracy: 0.34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9311075806617737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9182838797569275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9168893098831177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9031649231910706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.911853551864624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.909682035446167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8964174389839172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8977017998695374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9016806483268738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8885713815689087\n",
            "Validation Loss: 1.9236093759536743, Accuracy: 0.36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8884300589561462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.872288703918457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8893781900405884\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8960694074630737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8869677186012268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.873008906841278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.891036033630371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8675674200057983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8750654458999634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8817746043205261\n",
            "Validation Loss: 1.8848686814308167, Accuracy: 0.36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8583375811576843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8827233910560608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.852781593799591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.863670527935028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.86995267868042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8467293977737427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8456562161445618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8520023226737976\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8329458832740784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8491775393486023\n",
            "Validation Loss: 1.8483034074306488, Accuracy: 0.38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8380566239356995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8211448788642883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8416093587875366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.833822250366211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.817156970500946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8199020624160767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8389384746551514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.818708062171936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8361421823501587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8140105605125427\n",
            "Validation Loss: 1.8135414719581604, Accuracy: 0.38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8135610222816467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8331856727600098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.835495114326477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8071231842041016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8256674408912659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8174881339073181\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8045598268508911\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8077808022499084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7830559611320496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8012158274650574\n",
            "Validation Loss: 1.7809302806854248, Accuracy: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8013775944709778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7988121509552002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.794582724571228\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8017499446868896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7684805989265442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7945058345794678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7841486930847168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8034693002700806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8022058606147766\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8026604056358337\n",
            "Validation Loss: 1.7500783205032349, Accuracy: 0.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7737277746200562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8036286234855652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7797017097473145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7883883714675903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7784526348114014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7825552821159363\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7718709111213684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7791683077812195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7802099585533142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7804085612297058\n",
            "Validation Loss: 1.721586138010025, Accuracy: 0.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7427635788917542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.772345781326294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7507036328315735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.75075364112854\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7621873617172241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.74333918094635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.758155643939972\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7675806879997253\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7546894550323486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7415390014648438\n",
            "Validation Loss: 1.6951889395713806, Accuracy: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7531208395957947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.723136842250824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.728075385093689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.756837248802185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.732921302318573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7357593774795532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7303782105445862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7306267619132996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7406067848205566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7370315790176392\n",
            "Validation Loss: 1.6704608798027039, Accuracy: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7293192148208618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7055700421333313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.725757658481598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.714715301990509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.719088077545166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.750079095363617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7050374150276184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7153763175010681\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7167111039161682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7057337760925293\n",
            "Validation Loss: 1.6470391750335693, Accuracy: 0.52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6991853713989258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7150521874427795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7246984839439392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.716287612915039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6864622831344604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7247511148452759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.702700436115265\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7011532187461853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6992537379264832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7013089060783386\n",
            "Validation Loss: 1.6251075565814972, Accuracy: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7206335067749023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.688014268875122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6767684817314148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.686655342578888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.685020089149475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7064286470413208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6815001964569092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6957504749298096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6733915209770203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6910793781280518\n",
            "Validation Loss: 1.6049956977367401, Accuracy: 0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6832889318466187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7135361433029175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6637777090072632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.691058874130249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6599839329719543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6699337363243103\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6888709664344788\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6954888701438904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6719611287117004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.646501898765564\n",
            "Validation Loss: 1.5864416658878326, Accuracy: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6725288033485413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.653636872768402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6515762209892273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.670377790927887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.667078673839569\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.684049665927887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6550106406211853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6790630221366882\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                             "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.6600894927978516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "VAL_FREQUENCY = 10\n",
        "PATH1 = '/content/drive/MyDrive/LLM_Assignment/Model.pt'\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader_val, loss_fn, device):\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    accurate_predictions = 0\n",
        "    total_samples = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in dataloader_val:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          logits = model(input_ids, attention_mask=attention_mask)[0]\n",
        "\n",
        "        loss = loss_fn(logits, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        _, predictions = torch.max(logits, dim=1)\n",
        "        accurate_predictions += (predictions == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "        nb_eval_steps+=1\n",
        "\n",
        "    avg_loss = total_loss / nb_eval_steps\n",
        "    accuracy = accurate_predictions / total_samples\n",
        "    print(f\"Validation Loss: {avg_loss}, Accuracy: {accuracy}\")\n",
        "    return avg_loss\n",
        "\n",
        "def finetune(epochs, model, loss_fn, optimizer, dataloader_train, dataloader_val, device):\n",
        "    min_vloss = 10000\n",
        "    patience_index = 0\n",
        "    patience = 5\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        tr_loss = 0\n",
        "        nb_tr_steps = 0\n",
        "        loop = tqdm(enumerate(dataloader_train), leave=False, total=len(dataloader_train))\n",
        "\n",
        "        for step, batch in loop:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = loss_fn(outputs[0], labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_steps += 1\n",
        "\n",
        "        avg_train_loss = tr_loss / nb_tr_steps\n",
        "        print(\"Train loss: {}\".format(avg_train_loss))\n",
        "\n",
        "        if epoch % VAL_FREQUENCY == 0:\n",
        "            val_loss = evaluate(model, dataloader_val, loss_fn, device)\n",
        "            if val_loss <= min_vloss:\n",
        "                min_vloss = val_loss\n",
        "                torch.save(model.state_dict(), PATH1)\n",
        "                patience_index = 0\n",
        "            else:\n",
        "                patience_index += 1\n",
        "            if patience_index == patience:\n",
        "                break\n",
        "\n",
        "    return model\n",
        "model = finetune(200, model, loss_fn, optimizer, dataloader_train, dataloader_val, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1_6mGpCB_13"
      },
      "source": [
        "Test Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI83ZUczmrQ2",
        "outputId": "18621737-5504-41ff-bfbf-2f7d47bdce33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Labels: [0, 1, 2, 4, 2, 0, 4, 5, 5, 0, 4, 0, 3, 2, 5, 4, 1, 6, 1, 1]\n",
            "Predicted Labels: [2, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6]\n",
            "Test Accuracy: 20.00%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def evaluate_on_test(model, test_set):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_set:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)[0]\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(f\"True Labels: {true_labels}\")\n",
        "    print(f\"Predicted Labels: {predictions}\")\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "test_accuracy = evaluate_on_test(model, dataloader_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsUT9Dtr2Kbb"
      },
      "source": [
        "Fine-tune all parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IDJYMh-6z8HX"
      },
      "outputs": [],
      "source": [
        "training_set, test_set, validation_set = load_data(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ja8CiEye0E-g"
      },
      "outputs": [],
      "source": [
        "training_set['sample'] = 'training'\n",
        "validation_set['sample'] = 'validation'\n",
        "test_set['sample'] = 'test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k9STaUEo6X2Q"
      },
      "outputs": [],
      "source": [
        "num_classes = training_set['Domain'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odz50Cvp8HsS",
        "outputId": "77223b88-5c89-4a84-fa27-20556af94ad3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hV-kTOMw0FA_"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "all_sets = pd.concat([training_set, validation_set, test_set], axis=0)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "all_sets['Encoded_Domain'] = label_encoder.fit_transform(all_sets['Domain'])\n",
        "\n",
        "training_set = all_sets[all_sets['sample'] == 'training']\n",
        "validation_set = all_sets[all_sets['sample'] == 'validation']\n",
        "test_set = all_sets[all_sets['sample'] == 'test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL-xsXME0FDo",
        "outputId": "2287243f-f3c6-4bc2-8a85-bf7f83eba96d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def make_finetuning_data_distilbert(dataset):\n",
        "\n",
        "    labels = dataset['Encoded_Domain'].values\n",
        "\n",
        "    encoded = tokenizer.batch_encode_plus(\n",
        "        dataset['Abstract'],\n",
        "        add_special_tokens=True,\n",
        "        return_attention_mask=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'input_ids': encoded['input_ids'],\n",
        "        'attention_mask': encoded['attention_mask'],\n",
        "        'labels': torch.tensor(labels)\n",
        "    }\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "bert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "training_set = make_finetuning_data_distilbert(training_set)\n",
        "validation_set = make_finetuning_data_distilbert(validation_set)\n",
        "test_set = make_finetuning_data_distilbert(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IxnAOq6Y2V-O"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE_TRAIN = 32\n",
        "BATCH_SIZE_VAL = 16\n",
        "BATCH_SIZE_TEST = 16\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "class FTDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data['input_ids'])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'input_ids': self.data['input_ids'][index],\n",
        "            'attention_mask': self.data['attention_mask'][index],\n",
        "            'labels': self.data['labels'][index]\n",
        "        }\n",
        "\n",
        "dataset_train = FTDataset(training_set)\n",
        "dataloader_train = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE_TRAIN)\n",
        "dataset_val = FTDataset(validation_set)\n",
        "dataloader_val = DataLoader(dataset=dataset_val, batch_size=BATCH_SIZE_VAL)\n",
        "dataset_test = FTDataset(test_set)\n",
        "dataloader_test = DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE_TEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NFOb8vqpIplz"
      },
      "outputs": [],
      "source": [
        "bert_model_fullft = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "riihMKScBINa"
      },
      "outputs": [],
      "source": [
        "class FTModelFull(nn.Module):\n",
        "    def __init__(self, bert_model, num_classes, second_num_classes):\n",
        "        super(FTModelFull, self).__init__()\n",
        "        self.bert_model = bert_model\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(bert_model.config.hidden_size, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        # Additional classifier\n",
        "        self.second_classifier = nn.Linear(num_classes, second_num_classes)\n",
        "        self.second_softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "        logits = self.classifier(pooled_output)\n",
        "        probabilities = self.softmax(logits)\n",
        "\n",
        "        # Pass the output through the second classifier\n",
        "        second_logits = self.second_classifier(probabilities)\n",
        "        second_probabilities = self.second_softmax(second_logits)\n",
        "\n",
        "        return second_logits, second_probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bJnlh6be2rki"
      },
      "outputs": [],
      "source": [
        "# Initialize model but don't freeze Distilbert parameters\n",
        "model_full_ft = FTModelFull(bert_model_fullft, num_classes, num_classes).to('cuda')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_full_ft = model_full_ft.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "v2cuVWWn2vEH"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KycuSLjt2xrs",
        "outputId": "f3a550fc-7459-4aa4-a462-fcdc7e689a1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Choose parameters wisely!\n",
        "learning_rate = 2e-5\n",
        "adam_epsilon = 1e-8\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model_full_ft.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.2},\n",
        "    {'params': [p for n, p in model_full_ft.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EXazkme25t0",
        "outputId": "bb4af436-9de7-43ff-dc3c-952fa7a61101"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9644247889518738\n",
            "Validation Loss: 1.9453555047512054, Accuracy: 0.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9509192109107971\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9416365027427673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9280498027801514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.917827069759369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.9080519080162048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8980006575584412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8884796500205994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8803942799568176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8713381886482239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.857170283794403\n",
            "Validation Loss: 1.8254092931747437, Accuracy: 0.36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8486335277557373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8369040489196777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8264393210411072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8170443177223206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8091287016868591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.8013059496879578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7939849495887756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7883821725845337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7835643887519836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7793784141540527\n",
            "Validation Loss: 1.8141704201698303, Accuracy: 0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7750423550605774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7705166935920715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7661305665969849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.761139452457428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7580763697624207\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.752539336681366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7469048500061035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7444011569023132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.741435945034027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7377976179122925\n",
            "Validation Loss: 1.8078336119651794, Accuracy: 0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7353477478027344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7330126762390137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7306084036827087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7284159064292908\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7268155813217163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7250902652740479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7240005731582642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7222782969474792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7215207815170288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7196444272994995\n",
            "Validation Loss: 1.8030438721179962, Accuracy: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7186006903648376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7178491353988647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7175626158714294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7171627283096313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7166049480438232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7163475155830383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7158896327018738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7154839634895325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7150752544403076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.714928925037384\n",
            "Validation Loss: 1.7988813519477844, Accuracy: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.714699625968933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7145585417747498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7140427231788635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7138962745666504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.713526725769043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7127352356910706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.710715651512146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7099753618240356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.708152174949646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7075458765029907\n",
            "Validation Loss: 1.7974678874015808, Accuracy: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7074699401855469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7071110606193542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7068724632263184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7065925002098083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7065401077270508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7063642740249634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7061457633972168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.705927312374115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7057717442512512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7056569457054138\n",
            "Validation Loss: 1.7911417782306671, Accuracy: 0.52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7055429220199585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7055351734161377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7053186893463135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7051680088043213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7050792574882507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7049657702445984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7048330903053284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7047885060310364\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7046520113945007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7045778036117554\n",
            "Validation Loss: 1.7988111078739166, Accuracy: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.70440673828125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7044952511787415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7043153643608093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7041712999343872\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.704345703125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7040979266166687\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7039611339569092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7038320899009705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7038033604621887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.703701138496399\n",
            "Validation Loss: 1.7973912060260773, Accuracy: 0.52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.70378839969635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7034704685211182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7034342885017395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7032396793365479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.703186571598053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7030878067016602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7031378149986267\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7029587030410767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.702873945236206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.703017771244049\n",
            "Validation Loss: 1.7975557744503021, Accuracy: 0.54\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7027294039726257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7026064991950989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7025581002235413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.702422320842743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7023337483406067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.702258825302124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.702233076095581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7021033763885498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.702088475227356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7019977569580078\n",
            "Validation Loss: 1.798300862312317, Accuracy: 0.52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7019288539886475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7017910480499268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7017191648483276\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7016353011131287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7015718817710876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7015182971954346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7015318274497986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.701360046863556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.7012701034545898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                             "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.701372742652893\n",
            "Validation Loss: 1.799689382314682, Accuracy: 0.54\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "VAL_FREQUENCY = 10\n",
        "PATH1 = '/content/drive/MyDrive/LLM_Assignment/Model2.pt'\n",
        "\n",
        "# Function used to evaluate the model on\n",
        "# the validation set\n",
        "def evaluate(model, dataloader_val, loss_fn, device):\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_loss = 0\n",
        "    accurate_predictions = 0\n",
        "    total_samples = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dataloader_val:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          logits = model(input_ids, attention_mask=attention_mask)[0]\n",
        "\n",
        "        loss = loss_fn(logits, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        _, predictions = torch.max(logits, dim=1)\n",
        "        accurate_predictions += (predictions == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "        nb_eval_steps+=1\n",
        "\n",
        "    avg_loss = total_loss / nb_eval_steps\n",
        "    accuracy = accurate_predictions / total_samples\n",
        "    print(f\"Validation Loss: {avg_loss}, Accuracy: {accuracy}\")\n",
        "    return avg_loss\n",
        "\n",
        "def finetune(epochs, model, loss_fn, optimizer, dataloader_train, dataloader_val, device):\n",
        "    min_vloss = 10000\n",
        "    patience_index = 0\n",
        "    patience = 5\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        tr_loss = 0\n",
        "        nb_tr_steps = 0\n",
        "        loop = tqdm(enumerate(dataloader_train), leave=False, total=len(dataloader_train))\n",
        "\n",
        "        for step, batch in loop:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = loss_fn(outputs[0], labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_steps += 1\n",
        "\n",
        "        avg_train_loss = tr_loss / nb_tr_steps\n",
        "        print(\"Train loss: {}\".format(avg_train_loss))\n",
        "\n",
        "        if epoch % VAL_FREQUENCY == 0:\n",
        "            val_loss = evaluate(model, dataloader_val, loss_fn, device)\n",
        "            if val_loss <= min_vloss:\n",
        "                min_vloss = val_loss\n",
        "                torch.save(model.state_dict(), PATH1)\n",
        "                patience_index = 0\n",
        "            else:\n",
        "                patience_index += 1\n",
        "            if patience_index == patience:\n",
        "                break\n",
        "\n",
        "    return model\n",
        "model_full_ft = finetune(200, model_full_ft, loss_fn, optimizer, dataloader_train, dataloader_val, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLSlrYcSMXv9"
      },
      "source": [
        "Test Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q84v4KZiMTeU",
        "outputId": "723158b4-2b9f-4a57-da29-ba4c6d76ee84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Labels: [0, 1, 2, 4, 2, 0, 4, 5, 5, 0, 4, 0, 3, 2, 5, 4, 1, 6, 1, 1]\n",
            "Predicted Labels: [0, 0, 0, 4, 0, 6, 1, 1, 4, 0, 4, 0, 0, 0, 1, 4, 3, 6, 0, 3]\n",
            "Test Accuracy: 35.00%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def evaluate_on_test(model, test_set):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_set:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)[0]\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(f\"True Labels: {true_labels}\")\n",
        "    print(f\"Predicted Labels: {predictions}\")\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "test_accuracy = evaluate_on_test(model_full_ft, dataloader_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
